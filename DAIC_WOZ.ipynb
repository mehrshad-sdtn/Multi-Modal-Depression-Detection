{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIp4mlfJlyQD",
        "outputId": "16110717-d9f6-4e5a-dd08-6059778a45a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wave\n",
        "from google.colab import drive\n",
        "import tensorflow.compat.v1 as tf\n",
        "import zipfile\n",
        "import librosa\n",
        "from keras import layers\n",
        "import math\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "prefix = '/content/drive/MyDrive/DAIC-WOZ'\n",
        "assert os.path.exists(prefix), \"Data folder not found in Google Drive.\""
      ],
      "metadata": {
        "id": "ez3JlYtELwEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV files\n",
        "train_split_df = pd.read_csv(os.path.join(prefix, 'train_split_Depression_AVEC2017.csv'))\n",
        "test_split_df = pd.read_csv(os.path.join(prefix, 'dev_split_Depression_AVEC2017.csv'))\n",
        "\n",
        "train_split_num = train_split_df['Participant_ID'].tolist()\n",
        "test_split_num = test_split_df['Participant_ID'].tolist()\n",
        "train_split_label = train_split_df['PHQ8_Binary'].tolist()\n",
        "test_split_label = test_split_df['PHQ8_Binary'].tolist()\n",
        "\n",
        "# Load queries.txt\n",
        "with open(os.path.join(prefix, 'queries.txt')) as f:\n",
        "    queries = f.readlines()"
      ],
      "metadata": {
        "id": "0B8rXqyoiAO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_topics(sentence):\n",
        "    for query in queries:\n",
        "        query = query.strip('\\n')\n",
        "        sentence = sentence.strip('\\n')\n",
        "        if query == sentence:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "cluster_size = 16\n",
        "\n",
        "def wav2vlad(wave_data, sr):\n",
        "    global cluster_size\n",
        "    signal = wave_data\n",
        "    melspec = librosa.feature.melspectrogram(y=signal, n_mels=80, sr=sr).T\n",
        "    melspec = np.log(np.maximum(1e-6, melspec))\n",
        "    feature_size = melspec.shape[1]\n",
        "    max_samples = melspec.shape[0]\n",
        "    output_dim = cluster_size * 16\n",
        "    feat = NetVLAD(feature_size=feature_size, max_samples=max_samples, \\\n",
        "                            cluster_size=cluster_size, output_dim=output_dim) \\\n",
        "                                (tf.convert_to_tensor(melspec))\n",
        "    with tf.Session() as sess:\n",
        "        init = tf.global_variables_initializer()\n",
        "        sess.run(init)\n",
        "        r = feat.numpy()\n",
        "    return r\n",
        "\n",
        "class NetVLAD(layers.Layer):\n",
        "    \"\"\"Creates a NetVLAD class.\n",
        "    \"\"\"\n",
        "    def __init__(self, feature_size, max_samples, cluster_size, output_dim, **kwargs):\n",
        "\n",
        "        self.feature_size = feature_size\n",
        "        self.max_samples = max_samples\n",
        "        self.output_dim = output_dim\n",
        "        self.cluster_size = cluster_size\n",
        "        super(NetVLAD, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "    # Create a trainable weight variable for this layer.\n",
        "        self.cluster_weights = self.add_weight(name='kernel_W1',\n",
        "                                      shape=(self.feature_size, self.cluster_size),\n",
        "                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n",
        "                                      trainable=True)\n",
        "        self.cluster_biases = self.add_weight(name='kernel_B1',\n",
        "                                      shape=(self.cluster_size,),\n",
        "                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n",
        "                                      trainable=True)\n",
        "        self.cluster_weights2 = self.add_weight(name='kernel_W2',\n",
        "                                      shape=(1,self.feature_size, self.cluster_size),\n",
        "                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n",
        "                                      trainable=True)\n",
        "        self.hidden1_weights = self.add_weight(name='kernel_H1',\n",
        "                                      shape=(self.cluster_size*self.feature_size, self.output_dim),\n",
        "                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.cluster_size)),\n",
        "                                      trainable=True)\n",
        "\n",
        "        super(NetVLAD, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, reshaped_input):\n",
        "        \"\"\"Forward pass of a NetVLAD block.\n",
        "\n",
        "        Args:\n",
        "        reshaped_input: If your input is in that form:\n",
        "        'batch_size' x 'max_samples' x 'feature_size'\n",
        "        It should be reshaped in the following form:\n",
        "        'batch_size*max_samples' x 'feature_size'\n",
        "        by performing:\n",
        "        reshaped_input = tf.reshape(input, [-1, features_size])\n",
        "\n",
        "        Returns:\n",
        "        vlad: the pooled vector of size: 'batch_size' x 'output_dim'\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        In Keras, there are two way to do matrix multiplication (dot product)\n",
        "        1) K.dot : AxB -> when A has batchsize and B doesn't, use K.dot\n",
        "        2) tf.matmul: AxB -> when A and B both have batchsize, use tf.matmul\n",
        "\n",
        "        Error example: Use tf.matmul when A has batchsize (3 dim) and B doesn't (2 dim)\n",
        "        ValueError: Shape must be rank 2 but is rank 3 for 'net_vlad_1/MatMul' (op: 'MatMul') with input shapes: [?,21,64], [64,3]\n",
        "\n",
        "        tf.matmul might still work when the dim of A is (?,64), but this is too confusing.\n",
        "        Just follow the above rules.\n",
        "        \"\"\"\n",
        "        activation = tf.matmul(reshaped_input, self.cluster_weights)\n",
        "\n",
        "        activation += self.cluster_biases\n",
        "\n",
        "        activation = tf.nn.softmax(activation)\n",
        "\n",
        "        activation = tf.reshape(activation,\n",
        "                [-1, self.max_samples, self.cluster_size])\n",
        "\n",
        "        a_sum = tf.reduce_sum(activation,-2,keep_dims=True)\n",
        "\n",
        "        a = tf.multiply(a_sum,self.cluster_weights2)\n",
        "\n",
        "        activation = tf.transpose(activation,perm=[0,2,1])\n",
        "\n",
        "        reshaped_input = tf.reshape(reshaped_input,[-1,\n",
        "            self.max_samples, self.feature_size])\n",
        "\n",
        "        vlad = tf.matmul(activation,reshaped_input)\n",
        "        vlad = tf.transpose(vlad,perm=[0,2,1])\n",
        "        vlad = tf.subtract(vlad,a)\n",
        "        vlad = tf.nn.l2_normalize(vlad,1)\n",
        "        vlad = tf.reshape(vlad,[-1, self.cluster_size*self.feature_size])\n",
        "        vlad = tf.nn.l2_normalize(vlad,1)\n",
        "        vlad = tf.matmul(vlad, self.hidden1_weights)\n",
        "\n",
        "        return vlad\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.output_dim])\n",
        "\n",
        "def extract_features(number, extract_zip = False):\n",
        "    # Extract ZIP file\n",
        "    if extract_zip:\n",
        "        zip_path = os.path.join(prefix, f'{number}_P.zip')\n",
        "        extract_dir = os.path.join(prefix, f'{number}_P')\n",
        "\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "\n",
        "    # Load the transcript and audio data\n",
        "    transcript_path = os.path.join(prefix, f'{number}_P/{number}_TRANSCRIPT.csv')\n",
        "    audio_path = os.path.join(prefix, f'{number}_P/{number}_AUDIO.wav')\n",
        "\n",
        "    transcript = pd.read_csv(transcript_path, sep='\\t').fillna('')\n",
        "    wavefile = wave.open(audio_path, 'r')\n",
        "    sr = wavefile.getframerate()\n",
        "    nframes = wavefile.getnframes()\n",
        "    wave_data = np.frombuffer(wavefile.readframes(nframes), dtype=np.short)\n",
        "\n",
        "    response = ''\n",
        "    audio_feats = []\n",
        "    text_feats = []\n",
        "    signal = []\n",
        "\n",
        "    for t in transcript.itertuples():\n",
        "        # Check if the question is asked by \"Ellie\" and contains specific phrases\n",
        "        if getattr(t, 'speaker') == 'Ellie' and (identify_topics(getattr(t, 'value')) or 'i think i have asked everything' in getattr(t, 'value')):\n",
        "            if len(signal) == 0:\n",
        "                continue\n",
        "            audio_feats.append(wav2vlad(signal, sr))\n",
        "            text_feats.append(response)\n",
        "            response = ''\n",
        "            signal = []\n",
        "        elif getattr(t, 'speaker') == 'Participant':\n",
        "            if 'scrubbed_entry' in getattr(t, 'value'):\n",
        "                continue\n",
        "            start_time = int(getattr(t, 'start_time') * sr)\n",
        "            stop_time = int(getattr(t, 'stop_time') * sr)\n",
        "            response += ' ' + getattr(t, 'value')\n",
        "            signal = np.hstack((signal, wave_data[start_time:stop_time].astype(float)))\n",
        "\n",
        "    print(f'{number}_P feature done size {np.shape(audio_feats)}')\n",
        "\n",
        "    # Clean up extracted files to free up space\n",
        "    if extract_zip:\n",
        "        shutil.rmtree(extract_dir)\n",
        "    return audio_feats, text_feats"
      ],
      "metadata": {
        "id": "fvkH8r6vj0yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = os.path.join('/content/drive/MyDrive', 'DAIC-Features')\n",
        "\n",
        "# Ensure the directory exists; if not, create it\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "audio_features_train, text_features_train, targets_train = [], [], []\n",
        "audio_features_test, text_features_test, targets_test = [], [], []\n",
        "\n",
        "# Process training set\n",
        "print(\"Processing training data...\")\n",
        "for index in tqdm(range(len(train_split_num)), desc=\"Training Set\"):\n",
        "    audio_feats, text_feats = extract_features(train_split_num[index])\n",
        "    audio_features_train.append(audio_feats)\n",
        "    text_features_train.append(text_feats)\n",
        "    targets_train.append(train_split_label[index])\n",
        "\n",
        "print(\"Saving training data to Google Drive...\")\n",
        "# Save each audio feature and text feature list separately with participant IDs as keys\n",
        "np.savez(\n",
        "    os.path.join(save_dir, 'train_audio_clf.npz'),\n",
        "    **{f'audio_{train_split_num[i]}': feat for i, feat in enumerate(audio_features_train)}\n",
        ")\n",
        "np.savez(\n",
        "    os.path.join(save_dir, 'train_text_clf.npz'),\n",
        "    **{f'text_{train_split_num[i]}': feat for i, feat in enumerate(text_features_train)}\n",
        ")\n",
        "np.savez(\n",
        "    os.path.join(save_dir, 'train_label_clf.npz'),\n",
        "    **{f'label_{train_split_num[i]}': targets_train[i] for i in range(len(targets_train))}\n",
        ")\n",
        "\n",
        "# Process test set\n",
        "print(\"Processing test data...\")\n",
        "for index in tqdm(range(len(test_split_num)), desc=\"Test Set\"):\n",
        "    audio_feats, text_feats = extract_features(test_split_num[index])\n",
        "    audio_features_test.append(audio_feats)\n",
        "    text_features_test.append(text_feats)\n",
        "    targets_test.append(test_split_label[index])\n",
        "\n",
        "print(\"Saving test data to Google Drive...\")\n",
        "# Save each audio feature and text feature list separately with participant IDs as keys\n",
        "np.savez(\n",
        "    os.path.join(save_dir, 'test_audio_clf.npz'),\n",
        "    **{f'audio_{test_split_num[i]}': feat for i, feat in enumerate(audio_features_test)}\n",
        ")\n",
        "np.savez(\n",
        "    os.path.join(save_dir, 'test_text_clf.npz'),\n",
        "    **{f'text_{test_split_num[i]}': feat for i, feat in enumerate(text_features_test)}\n",
        ")\n",
        "np.savez(\n",
        "    os.path.join(save_dir, 'test_label_clf.npz'),\n",
        "    **{f'label_{test_split_num[i]}': targets_test[i] for i in range(len(targets_test))}\n",
        ")"
      ],
      "metadata": {
        "id": "fABZDWLdj_A3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae0c68a-8001-46d9-9039-7c995bca3107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing training data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Set:   1%|          | 1/107 [00:07<13:00,  7.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "303_P feature done size (34, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:   2%|▏         | 2/107 [00:13<11:55,  6.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304_P feature done size (46, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:   3%|▎         | 3/107 [00:22<13:14,  7.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "305_P feature done size (44, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:   4%|▎         | 4/107 [00:28<12:09,  7.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310_P feature done size (46, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:   5%|▍         | 5/107 [00:35<12:02,  7.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "312_P feature done size (41, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:   6%|▌         | 6/107 [00:41<11:22,  6.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313_P feature done size (42, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:   7%|▋         | 7/107 [00:51<12:55,  7.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315_P feature done size (47, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:   7%|▋         | 8/107 [00:59<12:56,  7.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "316_P feature done size (54, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:   8%|▊         | 9/107 [01:08<13:06,  8.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317_P feature done size (49, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:   9%|▉         | 10/107 [01:13<11:40,  7.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "318_P feature done size (38, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  10%|█         | 11/107 [01:20<11:26,  7.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "319_P feature done size (43, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  11%|█         | 12/107 [01:30<12:40,  8.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320_P feature done size (62, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  12%|█▏        | 13/107 [01:40<13:29,  8.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "321_P feature done size (58, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  13%|█▎        | 14/107 [01:49<13:33,  8.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "322_P feature done size (53, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  14%|█▍        | 15/107 [01:57<12:50,  8.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "324_P feature done size (43, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  15%|█▍        | 16/107 [02:02<11:32,  7.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "325_P feature done size (37, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  16%|█▌        | 17/107 [02:12<12:15,  8.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "326_P feature done size (56, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  17%|█▋        | 18/107 [02:20<12:18,  8.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "327_P feature done size (55, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  18%|█▊        | 19/107 [02:28<11:48,  8.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "328_P feature done size (41, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  19%|█▊        | 20/107 [02:35<11:25,  7.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "330_P feature done size (46, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  20%|█▉        | 21/107 [02:44<11:22,  7.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333_P feature done size (46, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  21%|██        | 22/107 [02:54<12:07,  8.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "336_P feature done size (55, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  21%|██▏       | 23/107 [03:00<11:04,  7.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "338_P feature done size (41, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  22%|██▏       | 24/107 [03:09<11:20,  8.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "339_P feature done size (48, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  23%|██▎       | 25/107 [03:16<10:50,  7.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "340_P feature done size (48, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  24%|██▍       | 26/107 [03:25<11:07,  8.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "341_P feature done size (46, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  25%|██▌       | 27/107 [03:34<11:22,  8.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "343_P feature done size (62, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  26%|██▌       | 28/107 [03:44<11:52,  9.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "344_P feature done size (53, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  27%|██▋       | 29/107 [03:51<10:43,  8.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "345_P feature done size (36, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  28%|██▊       | 30/107 [04:00<10:47,  8.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "347_P feature done size (50, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  29%|██▉       | 31/107 [04:10<11:18,  8.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "348_P feature done size (56, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  30%|██▉       | 32/107 [04:17<10:29,  8.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "350_P feature done size (44, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  31%|███       | 33/107 [04:27<10:47,  8.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "351_P feature done size (50, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  32%|███▏      | 34/107 [04:32<09:24,  7.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "352_P feature done size (32, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  33%|███▎      | 35/107 [04:40<09:31,  7.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "353_P feature done size (43, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  34%|███▎      | 36/107 [04:46<08:43,  7.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "355_P feature done size (38, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  35%|███▍      | 37/107 [04:55<08:53,  7.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "356_P feature done size (37, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  36%|███▌      | 38/107 [04:59<07:44,  6.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "357_P feature done size (30, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  36%|███▋      | 39/107 [05:06<07:47,  6.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "358_P feature done size (41, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  37%|███▋      | 40/107 [05:13<07:28,  6.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360_P feature done size (33, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  38%|███▊      | 41/107 [05:20<07:24,  6.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "362_P feature done size (42, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  39%|███▉      | 42/107 [05:28<07:43,  7.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "363_P feature done size (34, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  40%|████      | 43/107 [05:36<08:06,  7.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "364_P feature done size (43, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  41%|████      | 44/107 [05:44<07:56,  7.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "366_P feature done size (34, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  42%|████▏     | 45/107 [05:50<07:15,  7.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "368_P feature done size (29, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  43%|████▎     | 46/107 [05:57<07:13,  7.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "369_P feature done size (31, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  44%|████▍     | 47/107 [06:02<06:31,  6.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "370_P feature done size (26, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  45%|████▍     | 48/107 [06:13<07:35,  7.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "371_P feature done size (55, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  46%|████▌     | 49/107 [06:21<07:34,  7.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "372_P feature done size (44, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  47%|████▋     | 50/107 [06:29<07:39,  8.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "374_P feature done size (40, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  48%|████▊     | 51/107 [06:38<07:38,  8.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375_P feature done size (47, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  49%|████▊     | 52/107 [06:45<07:20,  8.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "376_P feature done size (40, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  50%|████▉     | 53/107 [06:53<07:03,  7.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "379_P feature done size (36, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  50%|█████     | 54/107 [07:01<07:09,  8.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "380_P feature done size (38, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  51%|█████▏    | 55/107 [07:10<07:04,  8.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383_P feature done size (35, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  52%|█████▏    | 56/107 [07:18<06:50,  8.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "385_P feature done size (49, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  53%|█████▎    | 57/107 [07:27<07:01,  8.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386_P feature done size (42, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  54%|█████▍    | 58/107 [07:35<06:46,  8.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391_P feature done size (48, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  55%|█████▌    | 59/107 [07:44<06:47,  8.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "392_P feature done size (44, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  56%|█████▌    | 60/107 [07:51<06:15,  7.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "393_P feature done size (40, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  57%|█████▋    | 61/107 [08:01<06:47,  8.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "397_P feature done size (55, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  58%|█████▊    | 62/107 [08:12<07:08,  9.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400_P feature done size (54, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  59%|█████▉    | 63/107 [08:20<06:35,  9.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "401_P feature done size (44, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  60%|█████▉    | 64/107 [08:29<06:27,  9.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "402_P feature done size (42, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  61%|██████    | 65/107 [08:35<05:36,  8.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "409_P feature done size (29, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  62%|██████▏   | 66/107 [08:46<06:04,  8.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "412_P feature done size (54, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  63%|██████▎   | 67/107 [08:54<05:44,  8.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "414_P feature done size (36, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  64%|██████▎   | 68/107 [09:02<05:34,  8.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "415_P feature done size (45, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  64%|██████▍   | 69/107 [09:13<05:51,  9.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "416_P feature done size (51, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  65%|██████▌   | 70/107 [09:20<05:16,  8.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "419_P feature done size (37, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  66%|██████▋   | 71/107 [09:31<05:35,  9.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "423_P feature done size (52, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  67%|██████▋   | 72/107 [09:41<05:25,  9.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "425_P feature done size (41, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  68%|██████▊   | 73/107 [09:49<05:11,  9.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "426_P feature done size (49, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  69%|██████▉   | 74/107 [10:00<05:11,  9.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "427_P feature done size (47, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  70%|███████   | 75/107 [10:10<05:10,  9.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "428_P feature done size (49, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  71%|███████   | 76/107 [10:19<04:59,  9.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "429_P feature done size (51, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  72%|███████▏  | 77/107 [10:30<04:54,  9.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "430_P feature done size (46, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  73%|███████▎  | 78/107 [10:39<04:45,  9.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "433_P feature done size (48, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  74%|███████▍  | 79/107 [10:47<04:20,  9.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "434_P feature done size (38, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  75%|███████▍  | 80/107 [11:01<04:45, 10.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "437_P feature done size (45, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  76%|███████▌  | 81/107 [11:15<05:04, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "441_P feature done size (69, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  77%|███████▋  | 82/107 [11:26<04:45, 11.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "443_P feature done size (53, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  78%|███████▊  | 83/107 [11:35<04:18, 10.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "444_P feature done size (38, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  79%|███████▊  | 84/107 [11:45<04:01, 10.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "445_P feature done size (44, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  79%|███████▉  | 85/107 [11:52<03:26,  9.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "446_P feature done size (35, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  80%|████████  | 86/107 [12:01<03:15,  9.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "447_P feature done size (39, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  81%|████████▏ | 87/107 [12:08<02:51,  8.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448_P feature done size (32, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  82%|████████▏ | 88/107 [12:16<02:41,  8.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "449_P feature done size (33, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  83%|████████▎ | 89/107 [12:30<03:00, 10.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "454_P feature done size (65, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  84%|████████▍ | 90/107 [12:37<02:33,  9.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "455_P feature done size (35, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  85%|████████▌ | 91/107 [12:48<02:34,  9.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "456_P feature done size (49, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  86%|████████▌ | 92/107 [12:59<02:30, 10.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "457_P feature done size (47, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  87%|████████▋ | 93/107 [13:11<02:28, 10.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "459_P feature done size (59, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  88%|████████▊ | 94/107 [13:21<02:18, 10.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "463_P feature done size (49, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  89%|████████▉ | 95/107 [13:32<02:06, 10.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "464_P feature done size (40, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  90%|████████▉ | 96/107 [13:39<01:44,  9.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "468_P feature done size (36, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  91%|█████████ | 97/107 [13:49<01:38,  9.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "471_P feature done size (43, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  92%|█████████▏| 98/107 [14:01<01:34, 10.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "473_P feature done size (55, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  93%|█████████▎| 99/107 [14:12<01:23, 10.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "474_P feature done size (46, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  93%|█████████▎| 100/107 [14:20<01:08,  9.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "475_P feature done size (38, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  94%|█████████▍| 101/107 [14:31<01:01, 10.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "478_P feature done size (49, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  95%|█████████▌| 102/107 [14:44<00:54, 10.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "479_P feature done size (55, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  96%|█████████▋| 103/107 [14:54<00:42, 10.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "485_P feature done size (49, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  97%|█████████▋| 104/107 [15:04<00:31, 10.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "486_P feature done size (44, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  98%|█████████▊| 105/107 [15:13<00:20, 10.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "487_P feature done size (36, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Set:  99%|█████████▉| 106/107 [15:21<00:09,  9.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "488_P feature done size (36, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Set: 100%|██████████| 107/107 [15:33<00:00,  8.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491_P feature done size (50, 1, 256)\n",
            "Saving training data to Google Drive...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing test data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Set:   3%|▎         | 1/35 [00:10<05:53, 10.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "302_P feature done size (36, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:   6%|▌         | 2/35 [00:19<05:24,  9.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "307_P feature done size (33, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:   9%|▊         | 3/35 [00:31<05:35, 10.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "331_P feature done size (42, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  11%|█▏        | 4/35 [00:43<05:50, 11.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "335_P feature done size (46, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  14%|█▍        | 5/35 [00:55<05:44, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "346_P feature done size (42, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  17%|█▋        | 6/35 [01:05<05:14, 10.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "367_P feature done size (32, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  20%|██        | 7/35 [01:16<05:11, 11.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "377_P feature done size (43, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  23%|██▎       | 8/35 [01:29<05:14, 11.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "381_P feature done size (46, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  26%|██▌       | 9/35 [01:42<05:14, 12.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "382_P feature done size (47, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  29%|██▊       | 10/35 [01:55<05:07, 12.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "388_P feature done size (46, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  31%|███▏      | 11/35 [02:11<05:25, 13.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "389_P feature done size (63, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  34%|███▍      | 12/35 [02:25<05:14, 13.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "390_P feature done size (49, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  37%|███▋      | 13/35 [02:38<04:54, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "395_P feature done size (47, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  40%|████      | 14/35 [02:47<04:16, 12.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "403_P feature done size (38, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  43%|████▎     | 15/35 [03:00<04:04, 12.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404_P feature done size (44, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  46%|████▌     | 16/35 [03:11<03:45, 11.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "406_P feature done size (40, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  49%|████▊     | 17/35 [03:23<03:36, 12.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "413_P feature done size (42, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  51%|█████▏    | 18/35 [03:33<03:14, 11.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "417_P feature done size (39, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  54%|█████▍    | 19/35 [03:45<03:04, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "418_P feature done size (43, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  57%|█████▋    | 20/35 [04:00<03:09, 12.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420_P feature done size (56, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  60%|██████    | 21/35 [04:11<02:50, 12.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "422_P feature done size (33, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  63%|██████▎   | 22/35 [04:23<02:38, 12.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "436_P feature done size (43, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  66%|██████▌   | 23/35 [04:34<02:20, 11.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "439_P feature done size (33, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  69%|██████▊   | 24/35 [04:48<02:15, 12.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440_P feature done size (52, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  71%|███████▏  | 25/35 [04:54<01:44, 10.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "451_P feature done size (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  74%|███████▍  | 26/35 [04:57<01:14,  8.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "458_P feature done size (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  77%|███████▋  | 27/35 [05:09<01:15,  9.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "472_P feature done size (44, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  80%|████████  | 28/35 [05:21<01:10, 10.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "476_P feature done size (44, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  83%|████████▎ | 29/35 [05:36<01:09, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "477_P feature done size (40, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  86%|████████▌ | 30/35 [05:46<00:55, 11.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "482_P feature done size (39, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  89%|████████▊ | 31/35 [06:00<00:47, 11.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "483_P feature done size (44, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  91%|█████████▏| 32/35 [06:12<00:35, 11.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "484_P feature done size (40, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  94%|█████████▍| 33/35 [06:25<00:24, 12.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "489_P feature done size (50, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest Set:  97%|█████████▋| 34/35 [06:39<00:12, 12.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "490_P feature done size (50, 1, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Set: 100%|██████████| 35/35 [06:50<00:00, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "492_P feature done size (41, 1, 256)\n",
            "Saving test data to Google Drive...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Usage\n",
        "save_dir = os.path.join('/content/drive/MyDrive', 'DAIC-Features')\n",
        "\n",
        "loaded_audio_data = np.load(os.path.join(save_dir, 'train_audio_clf.npz'))\n",
        "audio_feature_303 = loaded_audio_data['audio_303']  # Access data by participant ID\n",
        "\n",
        "loaded_audio_data = np.load(os.path.join(save_dir, 'train_text_clf.npz'))\n",
        "text_feature_303 = loaded_audio_data['text_303']  # Access data by participant ID\n",
        "\n",
        "loaded_audio_data = np.load(os.path.join(save_dir, 'train_label_clf.npz'))\n",
        "label_303 = loaded_audio_data['label_303']  # Access data by participant ID"
      ],
      "metadata": {
        "id": "9bh65P300kde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_feature_303.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG_Jhffn1c6m",
        "outputId": "a34c5de4-3c40-42bc-a6b1-fece2113162b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34, 1, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_feature_303[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmolBcNe0v7P",
        "outputId": "3b3cfdcb-17ee-40b5-ecd2-2a8b44d21426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\" okay how 'bout yourself\", ' here in california yeah',\n",
              "       \" oh well that it's big and broad there's a lot to do a lot of um um job opportunities than other states um pretty much that it's big and there's a lot you can do here\",\n",
              "       \" traffic um maybe the violence rate bad news even though you know you wanna know what's going on in your environment but you still have to watch it so you can you know look out to see what's going on on a daily basis\",\n",
              "       ' sociology i have a um two year degree in liberal arts but my major was sociology',\n",
              "       \" no i'm actually an m_t_a bus operator\",\n",
              "       \" well since metro is steady growing um my dream job is to move up in the company and i'm about to actually start some classes for supervisory next week so um 'cause they look to promote within the company so that's the good thing there's a lot of opportunities at metro where you can take classes and they'll pay for your tuition and things of that nature thanks\",\n",
              "       \" well it's not actually hard as right now it's easy if you take advantage of it right now 'cause they look to promote within so you know so since i'm already working there that's a good thing so it's good to go ahead and take the classes that you need that you're interested in and go ahead and move up the ladder as soon as possible \",\n",
              "       \" what do you mean i'm sorry okay\",\n",
              "       ' read take a long walk hot bath meditate just close my eyes sometimes',\n",
              "       \" i'm pretty much good because see by me being a bus operator you run into circumstances and situations you gotta remain calm and still remain professional at the same time\",\n",
              "       \" well i look at it like it it goes with i mean it comes with experience you know um you do something on a continuous basis usually you some somewhere down the line you become good at it you know so i i look at it like that so i've been driving for years and dealing with the public so it's just how you handle circumstances you you know treat people like you wanna be treated\",\n",
              "       \" no i'm pretty good at it now maybe when i was younger you know you as you get older you get wiser you learn different things and i'm still learning today\",\n",
              "       \" i would say my family you know my kids you know even though you know i had been having a lot of deaths around me but that's just go that's part of the life experience you know you born here but you gotta leave here one day but my kids will keep me you know sane and you know i love them and my family   thank you\",\n",
              "       ' no <laughter>',\n",
              "       \" um setting good examples you know because you're the first teacher you know and you wanna set a positive good example for your kids and i think that's a good thing and it starts at home\",\n",
              "       \" well um by you being the first teacher your kids you're you're their one that they see on a daily basis when they wake up so whatever's been taught in the home they lookin' and learning every day you know whether it's a home school you know people kids have a tendency to do things what they see you know what i mean  so you try to keep it positive teach 'em good morals and values and how to get along with other people regardless of race and you know different things of that nature\",\n",
              "       \" i have a um four and a half year old son i have a seven year old daughter and i also have a twenty three year old yeah i'm 'bout to be well my daughter's pregnant with a boy she has three um little girls so i have three grandkids and um one on the way which is a boy this time yeah thank you\",\n",
              "       \" the hardest thing is well right now i'm a single parent so that makes it hard alone itself you know and they can be expensive at times you know it depends on the person's situation you know the whether they have help or a job you know things of that nature to help the situation better but it's hard you know but you i try to you know keep a job keep food in the house you know just maintain and support my kids the best way i can\",\n",
              "       \" with my kids or just period what's memorable for me is that i'm the only one in my family with a degree so it's kinda like yeah it's kinda even though i'm the baby of ten kids you know and i've always kept that in the back of my mind even though everybody well pretty much my whole family have decent job but i'm the only one with a degree so i kinda like gave myself a pat on the back like you know you know i just that's the only thing i remember graduating you know and my family there and to support me  thank you\"],\n",
              "      dtype='<U1491')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_303"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM6-fyh47o4K",
        "outputId": "6e7da860-60bb-44ce-a6fc-ef2a1250ad6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(0)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q70mdc228GlS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}